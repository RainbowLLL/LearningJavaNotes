# 算法的时间复杂度

度量一个程序(算法)执行时间的两种方法：

1. 事后统计的方法：这种方法可行, 但是有两个问题：
   1. 一是要想对设计的算法的运行性能进行评测，需要实际运行该程序；
   2. 二是所得时间的统计量依赖于计算机的硬件、软件等环境因素, 这种方式，要在同一台计算机的相同状态下运行，才能比较那个算法速度更快。
2. 事前估算的方法：通过分析某个算法的**时间复杂度**来判断哪个算法更优.

## 时间频度$T(n)$

一个算法花费的时间与算法中语句的执行次数成正比例，哪个算法中语句执行次数多，它花费时间就多。一个算法中的语句执行次数称为**语句频度**或**时间频度**。记为$T(n)$。

例子：计算1-100所有数字之和

时间频度：$T(n)=n+1$

```java
int total = 0;
int end = 100;
//使用for循环计算
for(int i=1;i<=end;i++){
	total=+i;
}
```

时间频度：$T(n)=1$

```java
total = (1+end)*end/2;
```

### 忽略常数项

1. 2n+20 和 2n 随着n 变大，执行曲线无限接近, 20可以忽略
2. 3n+10 和 3n 随着n 变大，执行曲线无限接近, 10可以忽略

|      | $T(n)=2n+20$ | $T(n)=2*n$ | $T(3n+10)$ | $T(3n)$ |
| ---- | ------------ | ---------- | ---------- | ------- |
| 1    | 22           | 2          | 13         | 3       |
| 2    | 24           | 4          | 16         | 6       |
| 5    | 30           | 10         | 25         | 15      |
| 8    | 36           | 16         | 34         | 24      |
| 15   | 50           | 30         | 55         | 45      |
| 30   | 80           | 60         | 100        | 90      |
| 100  | 220          | 200        | 310        | 300     |
| 300  | 620          | 600        | 910        | 900     |

![image-20200908100959970](https://gitee.com/Reanon/upload-markdown-img/raw/master/img/20200908101000.png)



### 忽略低次项

1. $2n^2+3n+10$ 和 $2n^2$ 随着n 变大, 执行曲线无限接近, 可以忽略 3n+10
2. $n^2+5n+20$ 和 $n^2$ 随着n 变大,执行曲线无限接近, 可以忽略 5n+20

|      | $T(n)=2n^2+3n+10$ | $T(2n^2)$ | $T(n^2+5n+20)$ | $T(n^2)$ |
| ---- | ----------------- | --------- | -------------- | -------- |
| 1    | 15                | 2         | 26             | 1        |
| 2    | 24                | 8         | 34             | 4        |
| 5    | 75                | 50        | 70             | 25       |
| 8    | 162               | 128       | 124            | 64       |
| 15   | 505               | 450       | 320            | 225      |
| 30   | 1900              | 1800      | 1070           | 900      |
| 100  | 20310             | 20000     | 10520          | 10000    |



![image-20200908102209027](https://gitee.com/Reanon/upload-markdown-img/raw/master/img/20200908102209.png)

### 忽略系数

1. 随着n值变大，$5n^2+7n$ 和 $3n^2 + 2n$ ，执行曲线重合, 说明 这种情况下, 5和3可以忽略。
2. 而$n^3+5n$ 和 $6n^3+4n$ ，执行曲线分离，说明多少次方式关键

|      | $T(3n^2+2n)$ | $T(5n^2+7n)$ | $T(n^3+5n)$ | $T(6n^3+4n)$ |
| ---- | ------------ | ------------ | ----------- | ------------ |
| 1    | 5            | 12           | 6           | 10           |
| 2    | 16           | 34           | 18          | 56           |
| 5    | 85           | 160          | 150         | 770          |
| 8    | 208          | 376          | 552         | 3104         |
| 15   | 705          | 1230         | 3450        | 20310        |
| 30   | 2760         | 4710         | 27150       | 162120       |
| 100  | 30200        | 50700        | 1000500     | 6000400      |



![image-20200908102610963](https://gitee.com/Reanon/upload-markdown-img/raw/master/img/20200908102611.png)

## 

## 时间复杂度$O(f(n))$

一般情况下，算法中的基本操作语句的重复执行次数是问题规模n的某个函数，用时间频度$T(n)$表示；若有某个辅助函数$f(n$)，使得当n趋近于无穷大时，$\lim_{n\to \infty}\frac{T(n)}{f(n)}$ 的极限值为不等于零的常数，则称$f(n)$是$T(n)$的同数量级函数。记作 $T(n)=O(f(n)) $，称$O(f(n))$ 为算法的**渐进时间复杂度**，简称时间复杂度。

$T(n)$ 不同，但时间复杂度可能相同。 如：$T(n)=n²+7n+6$ 与 $T(n)=3n²+2n+2$ 它们的$T(n)$ 不同，但时间复杂度相同，都为$O(n²)$。

### 计算时间复杂度的方法

1. 用常数1代替运行时间中的所有加法常数 $T(n)=n^2+7n+6$ => $T(n)=n^2+7n+1$
2. 修改后的运行次数函数中，只保留最高阶项 $T(n)=n^2+7n+1$ => $T(n) = n^2$
3. 去除最高阶项的系数 $T(n) = n^2$ => $T(n) = n²$ => $O(n²)$

### 常见的时间复杂度

常见的算法时间复杂度由小到大依次为：$Ο(1)$＜$Ο(log_2^n)$＜Ο(n)＜$Ο(nlog_2^n)$＜$Ο(n^2)$＜$Ο(n^3)$＜ $Ο(n^k)$ ＜$Ο(2^n)$ ，随着问题规模n的不断增大，上述时间复杂度不断增大，算法的执行效率越低

1. 常数阶$O(1)$
2. 对数阶$O(log_2^n)$
3. 线性阶$O(n)$
4. 线性对数阶$O(nlog_2^n)$
5. 平方阶$O(n^2)$
6. 立方阶$O(n^3)$
7. k次方阶$O(n^k)$
8. 指数阶$O(2^n)$

从图中可见，我们应该尽可能避免使用指数阶的算法

![image-20200908104615402](https://gitee.com/Reanon/upload-markdown-img/raw/master/img/20200908104615.png)

#### 常数阶$O(1)$

无论代码执行了多少行，只要是**没有循环**等复杂结构，那这个代码的时间复杂度就都是$O(1)$

```java
int i = 1;
int j = 2;
++i;
j++;
int m = i + j;
```

上述代码在执行的时候，它消耗的时候并不随着某个变量的增长而增长，那么无论这类代码有多长，即使有几万几十万行，都可以用$O(1)$来表示它的时间复杂度。

#### 对数阶$O(log_2^n)$

对数阶：以2为底$n$的对数，有些书上记做$O(logN)$或者$O(lgN)$

- 一般地，在国内$lg$默认以10为底。
- 如果 $N=a^x(a>0,a\ne1)$ ，即$a$的x次方等于$N（a>0，且a≠1）$，那么数$x$叫做以$a$为底$N$的对数（logarithm），记作$x=log_a^N$。其中，a叫做对数的底数，N叫做真数，x叫做**以a为底N的对数**。

```java
int i = 1;
while(i < n){
	i = i * 2;
}
```

- 在while循环里面，每次都将 i 乘以 2，乘完之后，i 距离 n 就越来越近了。假设循环x次之后，i 就大于 2 了，此时这个循环就退出了，也就是说 2 的 x 次方等于 n，即 $x=log_2^n$.
- 也就是说当循环 $log_2^n$ 次以后，这个代码就结束了。因此这个代码的时间复杂度为：$O(log_2^n)$ 。$O(log_2^n)$ 的这个2 时间上是根据代码变化的，i = i * 3 ，则是 $O(log_3^n)$ 

#### 线性阶$O(n)$

for循环里面的代码会执行n遍，因此它消耗的时间是随着n的变化而变化的，因此这类代码都可以用$O(n)$来表示它的时间复杂度。

```java
for(i = 1;i <= n; ++i){
	j=i;
	j++;
}
```

#### 线性对数阶$O(nlog_2^n)$

线性对数阶$O(nlog_2^n)$其实非常容易理解，将时间复杂度为$O(log_2^n)$的代码循环N遍的话，那么它的时间复杂度就是 $n O(logN)$，也就是了$O(nlog_2^n)$

```java
for(m=1;m<n;m++){
	int i = 1;
	while(i < n){
		i = i * 2;
	}
}
```

#### 平方阶$O(n^2)$

平方阶$O(n^2)$ 就更容易理解了，如果把 O(n) 的代码再嵌套循环一遍，它的时间复杂度就是 $O(n^2)$，这段代码其实就是嵌套了2层n循环，它的时间复杂度就是 $O(n\times n)$，即 $O(n^2)$ 如果将其中一层循环的n改成m，那它的时间复杂度就变成了 $O(n\times m)$

```java
for(x = 1;i <= n; x++){
    for(i = 1;i <= n; ++i){
        j=i;
        j++;
    }
}
```

#### 立方阶$O(n^3)$

参考上面的$O(n^2)$去理解，$O(n^3)$相当于三层$n$循环

#### k次方阶$O(n^k)$

参考上面的$O(n^2)$去理解，$O(n^k)$相当于$k$层$n$循环

#### 指数阶$O(2^n)$



### 平均时间复杂度和最坏时间复杂度

1. 平均时间复杂度是指所有可能的输入实例均以等概率出现的情况下，该算法的运行时间。
2. 最坏情况下的时间复杂度称最坏时间复杂度。一般讨论的时间复杂度均是**最坏情况下的时间复杂度**。 这样做的原因是：最坏情况下的时间复杂度是算法在任何输入实例上运行时间的界限，这就保证了算法的运行时间不会比最坏情况更长。

| 排序法 |   平均时间   |    最差情形    | 稳定度 |  额外空间  | 备注                         |
| :----: | :----------: | :------------: | :----: | :--------: | ---------------------------- |
|  冒泡  |   $O(n^2)$   |    $O(n^2)$    |  稳定  |   $O(1)$   | n小时较好                    |
|  交换  |   $O(n^2)$   |    $O(n^2)$    | 不稳定 |   $O(1)$   | n小时较好                    |
|  选择  |    O(n^3)    |    $O(n^2)$    | 不稳定 |   $O(1)$   | n小时较好                    |
|  插入  |   $O(n^2)$   |    $O(n^2)$    |  稳定  |   $O(1)$   | 大部分己排序时较妇           |
|  基数  | $O(log_R^B)$ |  $O(log_R^B)$  |  稳定  |   $O(n)$   | B是真数(0-9) R是基数(个十百) |
| Shell  |  $O(nlogn)$  | $O(n^s)$ 1<s<2 | 不稳定 |   $O(1)$   | s是所选分组                  |
|  快速  |  $O(nlogn)$  |    $O(n^2)$    | 不稳定 | $O(nlogn)$ | n大时较好                    |
|  归并  |  $O(nlogn)$  |   $O(nlogn)$   |  稳定  |   $O(1)$   | n大时较好                    |
|   堆   |  $O(nlogn)$  |   $O(nlogn)$   | 不稳定 |   $O(1)$   | n大时较好                    |



## 空间复杂度

1. 类似于时间复杂度的讨论，一个算法的空间复杂度(Space Complexity)定义为该算法所耗费的存储空间，它也是问题规模n的函数。
2. 空间复杂度(Space Complexity)是对一个算法在运行过程中临时占用存储空间大小的量度。有的算法需要占用的临时工作单元数与解决问题的规模n有关，它随着n的增大而增大，当n较大时，将占用较多的存储单元，例如**快速排序**和**归并排序算法**就属于这种情况
3. 在做算法分析时，**主要讨论的是时间复杂度**。从用户使用体验上看，更看重的程序执行的速度。一些缓存产品(redis, memcache)和算法(基数排序)本质就是用空间换时间.